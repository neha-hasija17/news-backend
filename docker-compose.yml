version: '3.8'

services:
  news-backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: news-backend
    ports:
      - "8080:8080"
    environment:
      # Server Configuration
      - PORT=8080
      
      # Database Configuration
      - DB_PATH=/data/news.db
      
      # LLM Configuration (Groq by default)
      - LLM_PROVIDER=groq
      - GROQ_API_KEY=${GROQ_API_KEY}
      # Uncomment for OpenAI
      # - LLM_PROVIDER=openai
      # - OPENAI_API_KEY=${OPENAI_API_KEY}
      
      # LLM Models
      - INTENT_MODEL=llama-3.3-70b-versatile
      - SUMMARY_MODEL=llama-3.1-8b-instant
      - GROQ_BASE_URL=https://api.groq.com/openai/v1
      
      # Business Logic Configuration
      - DEFAULT_RADIUS=10.0
      - MAX_ARTICLES=5
      - SCORE_THRESHOLD=0.7
      
      # Trending Configuration
      - TRENDING_CACHE_TTL=300
      - TRENDING_RADIUS=50.0
      - TRENDING_TIME_WINDOW=24
    volumes:
      # Persist database
      - news-db:/data
      # Mount news data file
      - ./news_data.json:/root/news_data.json:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  news-db:
    driver: local
